Run time in 2025-01-30_11-47-23, Model:model_ConvNext_our更新内容：实验-model_v2_freq
Current Configuration:
        Model Name: model_ConvNext_our
        params: 31.381M
        flops: 12.435G
        depth_mult:3
        expansion:1
        Start Epoch: 0
        Total Epochs: 60
        Input Shape: [256, 256]
        Batch Size: 64
        Num Workers: 32
        Learning Rate: 5e-05
        weight_decay: 0.001
        Grad Clip: 5
        Training Annotation Path: ./data/DvXray_train.txt
        Validation Annotation Path: ./data/DvXray_val.txt
        Only Eval Mode: False
        Checkpoint: None
        use_ema: True
        use_amp: True
        alpha: 0.7
Epoch 1, lr:5.000e-05, train_mAP: 0.0284, train_loss:6.553e-01, val_mAP: 0.0698, val_precision:0.0150, val_recall:0.0532, val_f1_score:0.0207, val_ROC:0.7645, val_loss:5.6441e-01
Epoch 2, lr:8.379e-06, train_mAP: 0.0339, train_loss:3.954e-01, val_mAP: 0.0934, val_precision:0.0000, val_recall:0.0000, val_f1_score:0.0000, val_ROC:0.8511, val_loss:1.6934e-01
Epoch 3, lr:1.669e-05, train_mAP: 0.0510, train_loss:1.384e-01, val_mAP: 0.0933, val_precision:0.0000, val_recall:0.0000, val_f1_score:0.0000, val_ROC:0.8540, val_loss:9.4259e-02
Epoch 4, lr:2.498e-05, train_mAP: 0.0753, train_loss:9.603e-02, val_mAP: 0.1133, val_precision:0.0000, val_recall:0.0000, val_f1_score:0.0000, val_ROC:0.8665, val_loss:8.6987e-02
Epoch 5, lr:3.324e-05, train_mAP: 0.0897, train_loss:8.920e-02, val_mAP: 0.1663, val_precision:0.0000, val_recall:0.0000, val_f1_score:0.0000, val_ROC:0.8846, val_loss:8.3822e-02
Epoch 6, lr:4.149e-05, train_mAP: 0.1443, train_loss:8.349e-02, val_mAP: 0.2136, val_precision:0.0667, val_recall:0.0468, val_f1_score:0.0550, val_ROC:0.9001, val_loss:8.1180e-02
Epoch 7, lr:4.966e-05, train_mAP: 0.1746, train_loss:8.032e-02, val_mAP: 0.2787, val_precision:0.1333, val_recall:0.0582, val_f1_score:0.0664, val_ROC:0.9176, val_loss:7.2686e-02
Epoch 8, lr:4.926e-05, train_mAP: 0.2317, train_loss:7.560e-02, val_mAP: 0.3968, val_precision:0.3622, val_recall:0.1899, val_f1_score:0.1907, val_ROC:0.9294, val_loss:6.6992e-02
Epoch 9, lr:4.880e-05, train_mAP: 0.3345, train_loss:6.954e-02, val_mAP: 0.5681, val_precision:0.5546, val_recall:0.3780, val_f1_score:0.4153, val_ROC:0.9511, val_loss:5.3810e-02
Epoch 10, lr:4.829e-05, train_mAP: 0.4455, train_loss:6.155e-02, val_mAP: 0.6217, val_precision:0.6263, val_recall:0.4162, val_f1_score:0.4383, val_ROC:0.9543, val_loss:5.1527e-02
Epoch 11, lr:4.771e-05, train_mAP: 0.5010, train_loss:5.749e-02, val_mAP: 0.6624, val_precision:0.6942, val_recall:0.4847, val_f1_score:0.5405, val_ROC:0.9623, val_loss:4.3556e-02
Epoch 12, lr:4.709e-05, train_mAP: 0.5388, train_loss:5.397e-02, val_mAP: 0.7003, val_precision:0.7781, val_recall:0.5521, val_f1_score:0.6015, val_ROC:0.9675, val_loss:4.0822e-02
Epoch 13, lr:4.641e-05, train_mAP: 0.5705, train_loss:5.166e-02, val_mAP: 0.7117, val_precision:0.7781, val_recall:0.5571, val_f1_score:0.6223, val_ROC:0.9685, val_loss:3.9071e-02
Epoch 14, lr:4.568e-05, train_mAP: 0.5917, train_loss:4.944e-02, val_mAP: 0.7249, val_precision:0.7920, val_recall:0.5917, val_f1_score:0.6414, val_ROC:0.9711, val_loss:4.0243e-02
Epoch 15, lr:4.490e-05, train_mAP: 0.6203, train_loss:4.701e-02, val_mAP: 0.7464, val_precision:0.8062, val_recall:0.6336, val_f1_score:0.6752, val_ROC:0.9699, val_loss:3.6799e-02
Epoch 16, lr:4.408e-05, train_mAP: 0.6456, train_loss:4.479e-02, val_mAP: 0.7777, val_precision:0.8062, val_recall:0.6926, val_f1_score:0.7215, val_ROC:0.9722, val_loss:3.4637e-02
Epoch 17, lr:4.321e-05, train_mAP: 0.6715, train_loss:4.335e-02, val_mAP: 0.8023, val_precision:0.8267, val_recall:0.7002, val_f1_score:0.7455, val_ROC:0.9766, val_loss:3.0825e-02
Epoch 18, lr:4.230e-05, train_mAP: 0.6952, train_loss:4.135e-02, val_mAP: 0.8154, val_precision:0.8293, val_recall:0.7164, val_f1_score:0.7584, val_ROC:0.9786, val_loss:2.8789e-02
Epoch 19, lr:4.134e-05, train_mAP: 0.7194, train_loss:3.952e-02, val_mAP: 0.8198, val_precision:0.8265, val_recall:0.7104, val_f1_score:0.7482, val_ROC:0.9787, val_loss:2.8580e-02
Epoch 20, lr:4.036e-05, train_mAP: 0.7288, train_loss:3.838e-02, val_mAP: 0.8298, val_precision:0.8175, val_recall:0.7305, val_f1_score:0.7468, val_ROC:0.9806, val_loss:2.9767e-02
Epoch 21, lr:3.933e-05, train_mAP: 0.7325, train_loss:3.802e-02, val_mAP: 0.8497, val_precision:0.8448, val_recall:0.7611, val_f1_score:0.7938, val_ROC:0.9828, val_loss:2.6283e-02
Epoch 22, lr:3.828e-05, train_mAP: 0.7470, train_loss:3.660e-02, val_mAP: 0.8532, val_precision:0.8811, val_recall:0.7592, val_f1_score:0.8097, val_ROC:0.9830, val_loss:2.4953e-02
Epoch 23, lr:3.720e-05, train_mAP: 0.7679, train_loss:3.440e-02, val_mAP: 0.8528, val_precision:0.8611, val_recall:0.7514, val_f1_score:0.7868, val_ROC:0.9825, val_loss:2.5829e-02
Epoch 24, lr:3.609e-05, train_mAP: 0.7764, train_loss:3.391e-02, val_mAP: 0.8629, val_precision:0.8675, val_recall:0.7939, val_f1_score:0.8242, val_ROC:0.9844, val_loss:2.4375e-02
Epoch 25, lr:3.496e-05, train_mAP: 0.7760, train_loss:3.363e-02, val_mAP: 0.8671, val_precision:0.8523, val_recall:0.7813, val_f1_score:0.8057, val_ROC:0.9853, val_loss:2.5329e-02
Epoch 26, lr:3.381e-05, train_mAP: 0.7894, train_loss:3.298e-02, val_mAP: 0.8774, val_precision:0.8783, val_recall:0.8029, val_f1_score:0.8369, val_ROC:0.9853, val_loss:2.1742e-02
Epoch 27, lr:3.265e-05, train_mAP: 0.8011, train_loss:3.141e-02, val_mAP: 0.8794, val_precision:0.8757, val_recall:0.7892, val_f1_score:0.8247, val_ROC:0.9855, val_loss:2.2488e-02
Epoch 28, lr:3.147e-05, train_mAP: 0.8063, train_loss:3.089e-02, val_mAP: 0.8818, val_precision:0.8743, val_recall:0.8145, val_f1_score:0.8409, val_ROC:0.9861, val_loss:2.1536e-02
Epoch 29, lr:3.028e-05, train_mAP: 0.8079, train_loss:3.092e-02, val_mAP: 0.8832, val_precision:0.8901, val_recall:0.8062, val_f1_score:0.8428, val_ROC:0.9860, val_loss:2.2396e-02
Epoch 30, lr:2.909e-05, train_mAP: 0.8054, train_loss:3.122e-02, val_mAP: 0.8895, val_precision:0.8743, val_recall:0.8117, val_f1_score:0.8353, val_ROC:0.9864, val_loss:2.2479e-02
Epoch 31, lr:2.789e-05, train_mAP: 0.8158, train_loss:2.994e-02, val_mAP: 0.8849, val_precision:0.8792, val_recall:0.7975, val_f1_score:0.8303, val_ROC:0.9861, val_loss:2.3149e-02
Epoch 32, lr:2.669e-05, train_mAP: 0.8255, train_loss:2.904e-02, val_mAP: 0.8946, val_precision:0.9010, val_recall:0.7992, val_f1_score:0.8428, val_ROC:0.9869, val_loss:2.1790e-02
Epoch 33, lr:2.550e-05, train_mAP: 0.8355, train_loss:2.797e-02, val_mAP: 0.8887, val_precision:0.8807, val_recall:0.8080, val_f1_score:0.8370, val_ROC:0.9859, val_loss:2.2171e-02
Epoch 34, lr:2.431e-05, train_mAP: 0.8278, train_loss:2.893e-02, val_mAP: 0.8913, val_precision:0.8821, val_recall:0.8320, val_f1_score:0.8530, val_ROC:0.9862, val_loss:2.2125e-02
Epoch 35, lr:2.313e-05, train_mAP: 0.8433, train_loss:2.753e-02, val_mAP: 0.8930, val_precision:0.8807, val_recall:0.8164, val_f1_score:0.8425, val_ROC:0.9865, val_loss:2.3325e-02
Epoch 36, lr:2.197e-05, train_mAP: 0.8541, train_loss:2.601e-02, val_mAP: 0.8913, val_precision:0.8810, val_recall:0.8094, val_f1_score:0.8380, val_ROC:0.9863, val_loss:2.2633e-02
Epoch 37, lr:2.082e-05, train_mAP: 0.8531, train_loss:2.605e-02, val_mAP: 0.8948, val_precision:0.8772, val_recall:0.8349, val_f1_score:0.8528, val_ROC:0.9867, val_loss:2.1666e-02
Epoch 38, lr:1.969e-05, train_mAP: 0.8466, train_loss:2.671e-02, val_mAP: 0.9021, val_precision:0.8946, val_recall:0.8266, val_f1_score:0.8569, val_ROC:0.9871, val_loss:1.9990e-02
Epoch 39, lr:1.858e-05, train_mAP: 0.8590, train_loss:2.527e-02, val_mAP: 0.9006, val_precision:0.8972, val_recall:0.8300, val_f1_score:0.8576, val_ROC:0.9870, val_loss:2.0431e-02
Epoch 40, lr:1.750e-05, train_mAP: 0.8597, train_loss:2.531e-02, val_mAP: 0.9016, val_precision:0.8989, val_recall:0.8289, val_f1_score:0.8581, val_ROC:0.9864, val_loss:2.0524e-02
Epoch 41, lr:1.644e-05, train_mAP: 0.8682, train_loss:2.437e-02, val_mAP: 0.9092, val_precision:0.9050, val_recall:0.8327, val_f1_score:0.8617, val_ROC:0.9878, val_loss:1.9775e-02
Epoch 42, lr:1.542e-05, train_mAP: 0.8759, train_loss:2.353e-02, val_mAP: 0.9094, val_precision:0.8924, val_recall:0.8422, val_f1_score:0.8648, val_ROC:0.9883, val_loss:1.9298e-02
Epoch 43, lr:1.444e-05, train_mAP: 0.8707, train_loss:2.428e-02, val_mAP: 0.9085, val_precision:0.9001, val_recall:0.8340, val_f1_score:0.8625, val_ROC:0.9882, val_loss:2.0141e-02
Epoch 44, lr:1.348e-05, train_mAP: 0.8787, train_loss:2.319e-02, val_mAP: 0.9115, val_precision:0.8947, val_recall:0.8491, val_f1_score:0.8683, val_ROC:0.9884, val_loss:1.9329e-02
Epoch 45, lr:1.257e-05, train_mAP: 0.8798, train_loss:2.323e-02, val_mAP: 0.9095, val_precision:0.9002, val_recall:0.8409, val_f1_score:0.8663, val_ROC:0.9883, val_loss:1.9775e-02
Epoch 46, lr:1.170e-05, train_mAP: 0.8798, train_loss:2.314e-02, val_mAP: 0.9112, val_precision:0.9088, val_recall:0.8346, val_f1_score:0.8679, val_ROC:0.9881, val_loss:1.9201e-02
Epoch 47, lr:1.088e-05, train_mAP: 0.8880, train_loss:2.242e-02, val_mAP: 0.9102, val_precision:0.8863, val_recall:0.8497, val_f1_score:0.8648, val_ROC:0.9879, val_loss:1.9946e-02
Epoch 48, lr:1.010e-05, train_mAP: 0.8816, train_loss:2.283e-02, val_mAP: 0.9087, val_precision:0.8882, val_recall:0.8485, val_f1_score:0.8647, val_ROC:0.9884, val_loss:1.9974e-02
Epoch 49, lr:9.372e-06, train_mAP: 0.8912, train_loss:2.188e-02, val_mAP: 0.9107, val_precision:0.8858, val_recall:0.8516, val_f1_score:0.8658, val_ROC:0.9888, val_loss:1.9580e-02
Epoch 50, lr:8.693e-06, train_mAP: 0.8929, train_loss:2.146e-02, val_mAP: 0.9112, val_precision:0.9085, val_recall:0.8465, val_f1_score:0.8737, val_ROC:0.9890, val_loss:1.9397e-02
Epoch 51, lr:8.067e-06, train_mAP: 0.8827, train_loss:2.298e-02, val_mAP: 0.9132, val_precision:0.8981, val_recall:0.8499, val_f1_score:0.8710, val_ROC:0.9891, val_loss:1.9300e-02
Epoch 52, lr:7.495e-06, train_mAP: 0.8899, train_loss:2.218e-02, val_mAP: 0.9151, val_precision:0.9036, val_recall:0.8496, val_f1_score:0.8735, val_ROC:0.9892, val_loss:1.8903e-02
Epoch 53, lr:6.979e-06, train_mAP: 0.8921, train_loss:2.179e-02, val_mAP: 0.9138, val_precision:0.9030, val_recall:0.8513, val_f1_score:0.8735, val_ROC:0.9888, val_loss:1.9251e-02
Epoch 54, lr:6.520e-06, train_mAP: 0.8997, train_loss:2.090e-02, val_mAP: 0.9144, val_precision:0.8894, val_recall:0.8556, val_f1_score:0.8700, val_ROC:0.9891, val_loss:1.9363e-02
Epoch 55, lr:6.120e-06, train_mAP: 0.8954, train_loss:2.125e-02, val_mAP: 0.9130, val_precision:0.8984, val_recall:0.8486, val_f1_score:0.8696, val_ROC:0.9887, val_loss:1.9702e-02
Epoch 56, lr:5.780e-06, train_mAP: 0.8960, train_loss:2.109e-02, val_mAP: 0.9104, val_precision:0.8974, val_recall:0.8486, val_f1_score:0.8683, val_ROC:0.9873, val_loss:2.1196e-02
Epoch 57, lr:5.500e-06, train_mAP: 0.8913, train_loss:2.169e-02, val_mAP: 0.9134, val_precision:0.8971, val_recall:0.8505, val_f1_score:0.8709, val_ROC:0.9889, val_loss:1.9622e-02
Epoch 58, lr:5.282e-06, train_mAP: 0.8988, train_loss:2.100e-02, val_mAP: 0.9139, val_precision:0.9033, val_recall:0.8429, val_f1_score:0.8696, val_ROC:0.9891, val_loss:1.9306e-02
Epoch 59, lr:5.125e-06, train_mAP: 0.8969, train_loss:2.124e-02, val_mAP: 0.9133, val_precision:0.8979, val_recall:0.8455, val_f1_score:0.8678, val_ROC:0.9887, val_loss:1.9582e-02
Epoch 60, lr:5.031e-06, train_mAP: 0.8943, train_loss:2.158e-02, val_mAP: 0.9134, val_precision:0.9078, val_recall:0.8460, val_f1_score:0.8733, val_ROC:0.9891, val_loss:1.9408e-02
----------val----------
mAP: 0.915100634098053, precision:0.9035660028457642, recall:0.8495886921882629, f1_score:0.8734670877456665, ROC:0.9891728162765503
0.9790248274803162 0.8884156942367554 0.9632728695869446 0.9686917066574097 0.8863937258720398 0.7674030065536499 0.9630916714668274 1.0 0.6794042587280273 0.9431140422821045 0.9269752502441406 0.9927929043769836 0.9413103461265564 0.8395803570747375 0.9870386123657227 
----------test----------
mAP: 0.9098160862922668, precision:0.9101065397262573, recall:0.835135817527771, f1_score:0.867392897605896, ROC:0.9839404821395874
0.9948790669441223 0.8986011147499084 0.9761820435523987 0.9935570359230042 0.8347713947296143 0.5959032773971558 0.9976190328598022 1.0 0.7217507362365723 0.8211688995361328 0.9670124650001526 0.9993902444839478 0.9525411128997803 0.8981394171714783 0.9957249164581299 
----------diff----------
mAP: 0.6276958584785461, precision:0.6651515364646912, recall:0.50445556640625, f1_score:0.5604592561721802, ROC:0.8118792772293091
1.0 0.6163742542266846 0.6287148594856262 0.8333333134651184 0.8276175260543823 0.40684404969215393 0.625 0.0 0.7820395827293396 0.7407395839691162 0.8497452139854431 0.0 1.0 0.771695613861084 0.3333333432674408 
